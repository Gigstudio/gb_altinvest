# Журнал выполнения проекта "gb_altinvest"

*(Диплом по направлению "Специалист по ИИ", 2025)*

## 2025-05-21

### 1. Сформулирован план реализации дипломного проекта
- Определена основная идея работы: анализ взаимосвязи альтернативных данных (вакансии, новости) с котировками акций.
- Зафиксированы цели, задачи и ожидаемые результаты.

### 2. Выбран технологический стек
- Python (pandas, plotly, sklearn) — для анализа и визуализации данных
- PHP — для реализации веб-интерфейса
- Docker (docker-compose) — для изоляции и автоматизации развёртывания
- Airflow — для организации ETL и расписания
- (Опционально) Telegram-бот для доставки результатов

### 3. Попытка получения архивных котировок по Казахстану (KASE, AIX)
- Поиск архивных котировок по тикерам Kcell (KCEL), Halyk Bank (HSBK), КазАтомПром (KAP).
- Архив по индексу KASE отсутствует в пригодном виде, автоматизация невозможна.

### 4. Корректировка набора тикеров
- Исключён индекс KASE, рабочий набор: Kcell (KCEL), Halyk Bank (HSBK), КазАтомПром (KZAP).

### 5. Принят резервный план (на случай невозможности работы с KASE/AIX)
- Альтернатива: переход на российские тикеры с выгрузкой с moex.com.

### 6. Создан репозиторий и структура проекта
- Создан репозиторий на GitHub (`gb_altinvest`).
- Инициализирована рабочая папка, структура описана в README.md.

---

## 2025-05-22

### 7. Решение о сборе исторических котировок через Tradernet API
- Протестирован Tradernet Public API — получены исторические котировки, подтверждена пригодность.

### 8. Разработка контейнеризованного веб-сервиса
- Принята микросервисная архитектура (web, db, python, airflow, telegram-bot).

### 9. Настроены php.ini и vhosts/default.conf
- Отдельные конфиги php.ini и apache, подробности в README.md.

### 10. Реализован .htaccess для html/ и siteroot/
- Защита, маршрутизация, ограничения на уровне .htaccess.

### 11. Создан базовый index.php
- Подключение конфига, обработка ошибок, запуск приложения через $app->run().

### 12. Контейнер python-analysis для интеграции сбора данных
- Реализация REST-интеграции между Python и PHP через внутренний API.

### 13. Выполнена сборка и запуск через docker-compose
- Все контейнеры собраны, volume ./data/ смонтирован во все сервисы.

---

# Рутинные настройки volumes, служебные папки и .gitkeep фиксируются только в README.md, а не в history.md

## 2025-05-22

### 19. Создан и структурирован config/init.json для AltInSight
- Централизованное хранение параметров, описание в README.md.

### 20. Базовый web-контроллер для тестирования Tradernet API
- Позволяет получать котировки по тикеру, подготовлен к расширению.

### 21. Актуализирована структура проекта после реализации веб-сервиса
- Чёткая структура MVC: app/Core, app/Domain, app/Infrastructure, app/Presentation, API-хендлеры, разделённые data/python, data/tgbot и т.д.

### 22. Сервис экспорта котировок в JSON/CSV для Python-аналитики
- Котировки по каждому тикеру сохраняются в /data/quotes/ (JSON+CSV).

### 23. CLI-скрипт пакетного экспорта котировок
- export_all_quotes.php для автоматической выгрузки всех тикеров за указанный период.
- Исправлены ошибки путей и volumes.

### 24. Централизованный volume обмена данными
- Монтирование data/quotes/ и других папок между всеми контейнерами.

### 25. Тестирование обмена: выгрузка котировок, чтение в pandas
- Полный обменный цикл протестирован, форматы данных унифицированы.

### 26. Интеграция Apache Airflow и автоматизация экспорта данных
- Контейнер airflow, запуск через BashOperator, ежедневная выгрузка всех тикеров.

### 27. Архитектура сбора альтернативных данных (вакансии, новости, события)
- Каждый тип данных (вакансии, новости, события) — отдельный клиент/API, единый формат хранения, расписание Airflow, фронт-энд для визуализации.

### 28. Решение по интеграции PHP и Python-контейнеров
- Выбрана REST-интеграция: обмен только через внутренний API (web/API/index.php).

### 29. Регламент размещения скриптов и правил обмена файлами
- Все скрипты Python — в /data/python/scripts/
- Все выгрузки — в /data/quotes/, /data/vacancies/ и т.д.
- Все данные доступны и для PHP, и для Python (монтируются через volume).

### 30. Исправлены механизмы обработки API-запросов и ошибок
- Метод isApiStatic доработан: теперь всегда корректно распознаёт API-запросы, всегда отдаёт JSON.
- ErrorHandler и Controller — централизованный вывод ошибок в JSON (для API) и HTML (для сайта).

### 31. Страница альтернативных данных (AltData) с интеграцией HeadHunter API
- Страница "Альтернативные данные" с разметкой для вакансий, новостей, событий.
- PHP-клиент для HeadHunter (hh.kz), поиск по отрасли, агрегированные метрики.
- Все ошибки логируются, добавлен экспорт в /data/vacancies/{SYMBOL}.json.
- Кэширование через файловую систему (без обращения к API, если есть файл).

### 32. Автоматизация экспорта вакансий и котировок через Airflow
- DAG’и export_vacancies и export_quotes.
- Все данные по компаниям выгружаются в /data/vacancies/ и /data/quotes/.

### 33. Решение по новостям и событиям
- В связи с ограниченностью времени реализация сбора новостей и событий переносится в TODO (см. TODO.md).
- Вся архитектура для новостей и событий заложена: структура папок, методы saveAsJson, секции на фронте.
- К этому блоку вернёмся, если останется временной резерв.

---

## 2025-05-25—26

### 34. Интеграция с облачным хранилищем для передачи результатов (Google Drive → Dropbox)
- Первоначально реализована интеграция airflow + rclone + Google Drive для автоматической выгрузки /data/* в облако.
- Возникли трудности с Google Drive API и service account; для надёжности оперативно внедрена выгрузка в Dropbox (rclone, app token, настройки в init.json).
- Добавлен конфиг [dropbox] в rclone.conf, токен прописан в init.json и в rclone.conf (service config).
- Обновлён docker-compose для airflow, исправлены volume paths.
- В истории проекта зафиксирован выбор Dropbox как основного облака (до устранения проблем с Google Drive).

---

## 2025-05-26

### 35. Перенос этапа сбора новостей/событий в TODO (по времени)
- Документировано в истории: сбор новостей и событий по компаниям переносится в TODO.
- В приоритете — завершение анализа котировок, вакансий и зарплат.

### 36. План аналитического этапа (Google Colab)
- Файлы /data/quotes/*.json и /data/vacancies/*.json копируются на Google Диск.
- В Colab-ноутбуке:
    - Описывается цель анализа, структура исходных данных, примеры данных.
    - Анализируются временные ряды котировок, рассчитываются скользящие средние, медианы, квартиль, волатильность.
    - Анализируются вакансии: статистика по зарплатам, топ работодателей, распределение по регионам и времени.
    - Визуализация: графики с описанием, выводы.
- Ноутбук экспортируется в PDF/HTML, при необходимости делаются скриншоты для сдачи.

### 37. Фиксация архитектуры сайта и интеграции с аналитикой
- Несмотря на выполнение аналитики в Colab, результаты (графики, метрики) должны быть визуализированы и на сайте AltInSight.
- В планах — интеграция результатов анализа с фронт-эндом: отображение графиков и основных метрик на странице компании.
- Планируется автоматизация обновления данных (и/или ручная кнопка обновления) на сайте для предотвращения избыточных обращений к внешним API.

---

## ВАЖНО (оперативные пометки)
- Вся логика обмена и взаимодействия централизована через REST и папку /data/.
- Все промежуточные выгрузки формируются только один раз в сутки (или по требованию, вручную).
- Обновление файлов через DAG Airflow, хранение JSON (и CSV при необходимости) в общей папке.
- Приоритет: довести анализ котировок и вакансий до финального вида с красивой визуализацией и краткими выводами.
- Блок по новостям и событиям — отдельный этап, который реализуется только при наличии свободного времени.

---

## TODO.md (основные задачи на доработку)
- Автоматизация/ручное обновление выгруженных данных через фронт-энд сайта (без повторного обращения к API при наличии актуального файла).
- Кнопка принудительного обновления данных (quotes/vacancies) на сайте.
- (После основной сдачи) — добавить полноценный парсер новостей и событий, интеграцию с выбранным агрегатором новостей.
- Интеграция результатирующей аналитики (графики, инсайты) на страницу компании на сайте.
