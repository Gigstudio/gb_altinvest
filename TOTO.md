# TODO / Backlog (AltInSight Project)

### Критичные задачи ("на потом" из чата):

- [ ] **Кэширование данных:**  
  Сайт должен брать данные из `/data/quotes/`, `/data/vacancies/` (и т.д.), если они существуют, а не обращаться к внешним API при каждом запросе.
- [ ] **Обновление данных вручную:**  
  Сделать на веб-странице кнопку для принудительного обновления/дополнения котировок, вакансий и пр. (триггер DAG или запуск обновляющего скрипта).
- [ ] **Автоматизация получения новостей и событий:**  
  Найти и реализовать интеграцию с API для новостей и корпоративных событий по компаниям-тикерам (с возможностью локального хранения).
  Использовать API Tradernet, endpoint - 
- [x] **Единая точка для получения конфигурации:**  
  Использовать php_bridge/get_project_config.py во всех Python-скриптах, не дублировать функционал.
- [ ] **Графическая аналитика:**  
  Добавить отображение графиков по вакансиям и котировкам (после формирования базового датасета).
- [x] **Аналитика зарплат:**  
  Реализовать выгрузку/отображение средней зарплаты по отраслям, если возможно (искать источники).
  Данные получаются в рамках запроса данных по вакансиям.
- [ ] **Система кэширования и TTL:**  
  Добавить логику "устаревания" данных — если данные старше определённого срока, брать новые из API или выводить предупреждение.
- [ ] **Реализация экспорта новостей и событий по тикерам:**  
  Подготовить Python/PHP-скрипты, добавить DAG, интегрировать с API выбранного источника.
- [ ] **Добавить кнопку ручного обновления новостей/событий на фронте:**  
  По аналогии с котировками и вакансиями

### Текущая задача:

- [ ] **Веб-интерфейс — кэширование и ручное обновление данных:**  
  - Если в `/data/quotes/` и `/data/vacancies/` есть свежие файлы, брать данные из них.
  - При нажатии на кнопку "Обновить" — инициировать сбор новых данных через API и обновить файлы.
